### MedTourEasy_Deep learning Project
 ##  American Sign Language 
- This repository represents **" Action Recognition Using Alphapose "**.
- With the help of this project we can detect the human Actions/Activities based on the **Human Pose**.
  
## üìù Description
- The National Institute on Deafness and Other Communications Disorders (NIDCD) indicates that the 200-year-old American Sign Language is a complete, complex language (of which letter gestures are only part) but is the primary language for many deaf North Americans. Therefore, to build a system that can recognise sign language will help the deaf and hard-of-hearing better communicate using modern-day technologies. In this article, we will go through different architectures of CNN and see how it performs on classifying the Sign Language.


## ‚è≥ Dataset
- Download the dataset for Kaggle
- https://www.kaggle.com/datamunge/sign-language-mnist 

## :desktop_computer:	Installation

### :hammer_and_wrench: Requirements
* Python 3.5+
* numpy
* pandas
* matplotlib
* seaborn
* random
* Tensorflow
* Windows
## :gear: Setup
1. Install Tensorflow :-
```bash
! pip install tensorflow

```
2. Install :-
```bash
! pip install numpy
```
```bash
```bash
! pip install pandas
```
```bash
```bash
! pip install matplotlib
```
```bash
```bash
! pip install seaborn
```
```bash
```bash
! pip install random
```
```bash

### :Report: Please Go through [Medtoureasy Report.pdf](https://github.com/MrShubham1267/MedTourEasy__ASL_Project/blob/main/Medtoureasy%20Report.pdf) for more info.
