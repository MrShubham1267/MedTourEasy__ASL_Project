### MedTourEasy_Deep learning Project
 ##  American Sign Language 
- This repository represents **" Action Recognition Using Alphapose "**.
- With the help of this project we can detect the human Actions/Activities based on the **Human Pose**.
  
## üìù Description
- The National Institute on Deafness and Other Communications Disorders (NIDCD) indicates that the 200-year-old American Sign Language is a complete, complex language (of which letter gestures are only part) but is the primary language for many deaf North Americans. Therefore, to build a system that can recognise sign language will help the deaf and hard-of-hearing better communicate using modern-day technologies. In this article, we will go through different architectures of CNN and see how it performs on classifying the Sign Language.


## ‚è≥ Dataset
- Download the dataset for Kaggle
- https://www.kaggle.com/datamunge/sign-language-mnist 

## :desktop_computer:	Installation

### :hammer_and_wrench: Requirements
* Python 3.5+
* numpy
* pandas
* matplotlib
* seaborn
* random
* Tensorflow
## :gear: Setup
1. Install Tensorflow :-
```bash
$ pip install tensorflow

```
2. Install :-
```bash
$ export PATH=/usr/local/cuda/bin/:$PATH

```
```bash

```bash
$ export PATH=/usr/local/cuda/bin/:$PATH

```
```bash

```bash
$ export PATH=/usr/local/cuda/bin/:$PATH

```
```bash


### :Report: Please Go through [Pose_With_Action_HLD2.docx](https://github.com/MrShubham1267/MedTourEasy__ASL_Project/blob/main/Medtoureasy%20Report.pdf) for more info.
